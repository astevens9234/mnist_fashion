root - INFO - 
 Using device: cuda 
 batch_size: 128 
 num_workers: 1 
 learning_rate: 0.001 
 epochs: 10 

root - INFO - 
 model: ResNet18(
  (net): Sequential(
    (0): Sequential(
      (0): LazyConv2d(0, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
      (1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
    (b2): Sequential(
      (0): Residual(
        (conv1): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Residual(
        (conv1): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (b3): Sequential(
      (0): Residual(
        (conv1): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (conv2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv3): LazyConv2d(0, 128, kernel_size=(1, 1), stride=(2, 2))
        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Residual(
        (conv1): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): LazyConv2d(0, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (b4): Sequential(
      (0): Residual(
        (conv1): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (conv2): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv3): LazyConv2d(0, 256, kernel_size=(1, 1), stride=(2, 2))
        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Residual(
        (conv1): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): LazyConv2d(0, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (b5): Sequential(
      (0): Residual(
        (conv1): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (conv2): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv3): LazyConv2d(0, 512, kernel_size=(1, 1), stride=(2, 2))
        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Residual(
        (conv1): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (conv2): LazyConv2d(0, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (bn1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn2): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (last): Sequential(
      (0): AdaptiveMaxPool2d(output_size=(1, 1))
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): LazyLinear(in_features=0, out_features=10, bias=True)
    )
  )
) 
 lossfx: CrossEntropyLoss() 
 optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
) 

root - INFO - Epoch 1
-------------------------------
root - INFO - loss: 2.300478  [  128/60000]
root - INFO - loss: 0.518049  [12928/60000]
root - INFO - loss: 0.345878  [25728/60000]
root - INFO - loss: 0.362936  [38528/60000]
root - INFO - loss: 0.385050  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 87.8%, Avg loss: 0.343197 

root - INFO - Epoch 2
-------------------------------
root - INFO - loss: 0.249381  [  128/60000]
root - INFO - loss: 0.321498  [12928/60000]
root - INFO - loss: 0.290212  [25728/60000]
root - INFO - loss: 0.354804  [38528/60000]
root - INFO - loss: 0.450360  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 88.8%, Avg loss: 0.310587 

root - INFO - Epoch 3
-------------------------------
root - INFO - loss: 0.242671  [  128/60000]
root - INFO - loss: 0.323370  [12928/60000]
root - INFO - loss: 0.271559  [25728/60000]
root - INFO - loss: 0.291124  [38528/60000]
root - INFO - loss: 0.231565  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 87.7%, Avg loss: 0.337907 

root - INFO - Epoch 4
-------------------------------
root - INFO - loss: 0.307275  [  128/60000]
root - INFO - loss: 0.190422  [12928/60000]
root - INFO - loss: 0.173422  [25728/60000]
root - INFO - loss: 0.486193  [38528/60000]
root - INFO - loss: 0.275040  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 89.9%, Avg loss: 0.271212 

root - INFO - Epoch 5
-------------------------------
root - INFO - loss: 0.137614  [  128/60000]
root - INFO - loss: 0.216617  [12928/60000]
root - INFO - loss: 0.177347  [25728/60000]
root - INFO - loss: 0.168538  [38528/60000]
root - INFO - loss: 0.212195  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 90.0%, Avg loss: 0.289576 

root - INFO - Epoch 6
-------------------------------
root - INFO - loss: 0.188825  [  128/60000]
root - INFO - loss: 0.193866  [12928/60000]
root - INFO - loss: 0.171151  [25728/60000]
root - INFO - loss: 0.212084  [38528/60000]
root - INFO - loss: 0.213350  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 89.9%, Avg loss: 0.273560 

root - INFO - Epoch 7
-------------------------------
root - INFO - loss: 0.257210  [  128/60000]
root - INFO - loss: 0.186813  [12928/60000]
root - INFO - loss: 0.133915  [25728/60000]
root - INFO - loss: 0.181462  [38528/60000]
root - INFO - loss: 0.188480  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 89.7%, Avg loss: 0.292293 

root - INFO - Epoch 8
-------------------------------
root - INFO - loss: 0.176445  [  128/60000]
root - INFO - loss: 0.200532  [12928/60000]
root - INFO - loss: 0.088783  [25728/60000]
root - INFO - loss: 0.247242  [38528/60000]
root - INFO - loss: 0.140607  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 89.9%, Avg loss: 0.286059 

root - INFO - Epoch 9
-------------------------------
root - INFO - loss: 0.187079  [  128/60000]
root - INFO - loss: 0.161288  [12928/60000]
root - INFO - loss: 0.155043  [25728/60000]
root - INFO - loss: 0.184810  [38528/60000]
root - INFO - loss: 0.080819  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 90.2%, Avg loss: 0.273708 

root - INFO - Epoch 10
-------------------------------
root - INFO - loss: 0.133282  [  128/60000]
root - INFO - loss: 0.127560  [12928/60000]
root - INFO - loss: 0.082704  [25728/60000]
root - INFO - loss: 0.305634  [38528/60000]
root - INFO - loss: 0.184406  [51328/60000]
root - INFO - Test Error: 
 Accuracy: 91.0%, Avg loss: 0.268254 

root - INFO - Finished!
